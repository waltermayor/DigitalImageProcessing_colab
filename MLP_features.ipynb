{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "MLP_features.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltermayor/DigitalImageProcessing_colab/blob/master/MLP_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uSLhMpUtPw3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "a673f022-628c-4396-f9ce-090e1bfdbf17"
      },
      "source": [
        "import numpy as np\n",
        "#import keras as k\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "% pip install opencv-contrib-python==3.2.0.7"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zrTrBjraNFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayColor2(a, b,title1 = \"Original\", title2 = \"Edited\"):\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.subplot(131), plt.imshow(a), plt.title(title1)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(132), plt.imshow(b), plt.title(title2)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi75SO49Pw3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_inputs = 32*32*3       # flattening each image to provide as input.  #  trying to form a model in the shape of a tunnel\n",
        "n_hidden1 = 400        # Num of nodes in hidden layer 1.\n",
        "n_hidden2 = 250        \n",
        "n_hidden3 = 64\n",
        "n_outputs = 10        # Number of final outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS0fn9dcPw36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now declare the input and output placeholders. \n",
        "# Placeholders let us use different userdefined inputs in the first and last layers \n",
        "\n",
        "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")  #The None values can be taken as i/p's from user later.\n",
        "y = tf.placeholder(tf.int32, shape=(None), name = \"y\")\n",
        "training = tf.placeholder_with_default(False, shape=(), name='training')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6lQOqtQPw4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### This function is not used in the code below - It is just for personal reference.\n",
        "def neural_layer(X, n_neurons, name, activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        std_dev = 2/np.sqrt(n_inputs)   # Inorder to not let the SGD algo break or explode, it is essential to initialize the \n",
        "                                        # variables. Initializing randomly using a truncated normal distribution with a \n",
        "                                        # std_dev of 2/ sqrt(n_inputs) can drastically improve the performance of the nn.\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = std_dev)\n",
        "        W = tf.Variable(init, name = \"Kernel\")\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name = \"bias\")\n",
        "        Z = tf.matmul(X, W) + b;\n",
        "        if activation is not None:\n",
        "            return activation(Z)\n",
        "        else:\n",
        "            return Z\n",
        "\n",
        "##Instead of this function we can use tensorflow inbuilt function - tf.layers.dense() to achieve the same purpose."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-iaB4rPw4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "510de7fc-876d-453d-9628-84fb49926349"
      },
      "source": [
        "from functools import partial  # The batch normalization can be automated using \"partial\" - but i havent done that below\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
        "\n",
        "batch_norm_momentum = 0.9\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    \n",
        "    #### Different initializers\n",
        "    \n",
        "    #he_init = tf.variance_scaling_initializer()  - around 45% acc (SGD)\n",
        "    #he_init = tf.random_uniform_initializer()    - around 46.5% acc (SGD)\n",
        "    he_init = tf.contrib.layers.xavier_initializer()  # - 48% accuracy (SGD) , upto 50% using Adam\n",
        "    \n",
        "    #### 3 Hidden layers, each using relu activation function\n",
        "\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
        "    bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9) \n",
        "    # Momentum of 0.9 is best known for optimization.\n",
        "    bn1Activation = tf.nn.relu(bn1)\n",
        "    \n",
        "    hidden2 = tf.layers.dense(bn1Activation, n_hidden2, name = \"hidden2\")\n",
        "    bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
        "    bn2Activation = tf.nn.relu(bn2)\n",
        "\n",
        "    hidden3 = tf.layers.dense(bn2Activation, n_hidden3, name = \"hidden3\")\n",
        "    bn3 = tf.layers.batch_normalization(hidden3, training = training, momentum = 0.9)\n",
        "    bn3Activation = tf.nn.relu(bn3)\n",
        "    logits_before_bn = tf.layers.dense(bn3Activation, n_outputs, name = \"outputs\") \n",
        "    \n",
        "    # NOTE:: logits are the nn outputs before classifying/ or activation layer\n",
        "    #logits = tf.nn.softmax(my_batch_norm_layer(logits_before_bn))\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits =logits_before_bn)\n",
        "    # \"labels\": vector must provide a single specific index for the true class\n",
        "    \n",
        "    # WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency.\n",
        "    # Do not call this op with the output of softmax, as it will produce incorrect results.\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "    \n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.05, epsilon=1e-06, use_locking=True,name='Adam')\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits_before_bn, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-126cf996b037>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-126cf996b037>:18: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWxo4wQnPw4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()      #initializes the tf.variable/constant/placeholders declared above\n",
        "#he_init = tf.contrib.layers.xavier_initializer()\n",
        "saver = tf.train.Saver()                      # helps to save the model and reuse later."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K068ZEcRPw4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f91083c7-b0bb-4510-bbc8-c3ab8ad1c918"
      },
      "source": [
        "### Now load the data\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNosMxnxPw4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "fa915687-fbd7-41f5-8a29-9ed64fde67bd"
      },
      "source": [
        "print(\"Shape of training data:\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"Shape of test data:\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train[1])\n",
        "print(y_train[2])\n",
        "\n",
        "displayColor2(X_train[1],X_train[2])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data:\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "Shape of test data:\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n",
            "[9]\n",
            "[9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAFqCAYAAABS9k9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrlOBIGtfCQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "38e3ec9e-9f80-4f9e-9611-eba082340f31"
      },
      "source": [
        "\n",
        "gray= cv2.cvtColor(X_train[7],cv2.COLOR_BGR2GRAY)\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "#kp = sift.detect(gray,None)\n",
        "kp, des = sift.detectAndCompute(gray,None)\n",
        "#gb = Image.fromarray(X_train[1])\n",
        "img=cv2.drawKeypoints(gray,kp,outImage=np.array([]),flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "#displayColor2(X_train[1],img)\n",
        "print(len(kp),len(des))\n",
        "print(len(des[1]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 11\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUHw6YM5Pw4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "89d5d1e7-4193-4ca1-ae40-152315f12be5"
      },
      "source": [
        "# Transforming label indices to one-hot encoded vectors \n",
        "\n",
        "## No need to convert to one hot now, we have done later in the code. \n",
        "## in tn.softmax_with_crossentropy_with_logits, the labels argument asks for the index of actual class. Therefore, we halt one\n",
        "## hot encoding as of now.\n",
        "\n",
        "#y_train = to_categorical(y_train, num_classes=10)\n",
        "#y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Transforming images from (32,32,3) to a single vector of size (32*32*3) {32*32*3 = 3072}\n",
        "\n",
        "X_train = np.reshape(X_train,(50000,3072))\n",
        "X_test = np.reshape(X_test,(10000,3072))\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalization of pixel values (to [0-1] range) # converting uint8 to double format\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6e469be64588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 138240000 into shape (50000,3072)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIpKZUxXPw4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now divide the test and train datasets into 3 parts, training set, validation set, and testing set\n",
        "# Considering the validation set to have 5000 images\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etFFk6NzPw4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b46db7ef-ca54-4f0f-8057-074b0c0f071e"
      },
      "source": [
        "print(X_train.shape, y_train.shape)     #Just to have a clear idea of the training/ validation/testing shapes of tensors\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 3072) (45000, 1)\n",
            "(5000, 3072) (5000, 1)\n",
            "(10000, 3072) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tdYOeQhPw4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 25\n",
        "batch_size = 6000 \n",
        "# If batch size is less like 100 or so, acc will fluctuate like 44% 20% 55% etc erratically due to underfitting nature\n",
        "\n",
        "# A function to shuffle the whole data set and select different batches randomly with replacement.\n",
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch                         # returns the first batch that was formed.\n",
        "        \n",
        "# Yeild is similar to return, the fun or loop runs untill it hits yeild, then what ever the first value of that variable is,\n",
        "# at that moment, it gets returned, and the loop continues."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMbGXNhPw44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "228bf2b8-3266-48a4-8545-d940904b2dba"
      },
      "source": [
        "# Now lets test the model with the built model on Validation Set\n",
        "\n",
        "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "# tf.get_collection(), which can find some tensor that you want,\n",
        "# UPDATE_OPS is a collection of ops (operations performed when the graph runs, like multiplication, ReLU, etc.), not variables. \n",
        "#y = tf.placeholder(tf.int32, shape=(None,10), name=\"y\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run([training_op, extra_update_ops],\n",
        "                     feed_dict={training: True, X: X_batch, y: y_batch.reshape([-1])})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid.reshape([-1])})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.104\n",
            "1 Validation accuracy: 0.092\n",
            "2 Validation accuracy: 0.092\n",
            "3 Validation accuracy: 0.1364\n",
            "4 Validation accuracy: 0.1518\n",
            "5 Validation accuracy: 0.1346\n",
            "6 Validation accuracy: 0.1614\n",
            "7 Validation accuracy: 0.1096\n",
            "8 Validation accuracy: 0.0972\n",
            "9 Validation accuracy: 0.092\n",
            "10 Validation accuracy: 0.092\n",
            "11 Validation accuracy: 0.092\n",
            "12 Validation accuracy: 0.092\n",
            "13 Validation accuracy: 0.092\n",
            "14 Validation accuracy: 0.092\n",
            "15 Validation accuracy: 0.092\n",
            "16 Validation accuracy: 0.092\n",
            "17 Validation accuracy: 0.0972\n",
            "18 Validation accuracy: 0.092\n",
            "19 Validation accuracy: 0.092\n",
            "20 Validation accuracy: 0.092\n",
            "21 Validation accuracy: 0.11\n",
            "22 Validation accuracy: 0.092\n",
            "23 Validation accuracy: 0.092\n",
            "24 Validation accuracy: 0.096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ok1tEBIPw4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "26c47373-f3e6-4ea3-c98f-3fd18dfaf25f"
      },
      "source": [
        "# Once accuracy over validation set is satisfactory, test the results on test set\n",
        "\n",
        "n_epochs = 25\n",
        "batch_size = 5000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run([training_op, extra_update_ops],\n",
        "                     feed_dict={training: True, X: X_batch, y: y_batch.reshape([-1])})\n",
        "        if epoch % 2 == 0:\n",
        "            accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test.reshape([-1])})\n",
        "            print(epoch, \"TestSet accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_cifar10_model_final.ckpt\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 TestSet accuracy: 0.1\n",
            "2 TestSet accuracy: 0.1\n",
            "4 TestSet accuracy: 0.1\n",
            "6 TestSet accuracy: 0.1108\n",
            "8 TestSet accuracy: 0.1\n",
            "10 TestSet accuracy: 0.1\n",
            "12 TestSet accuracy: 0.1357\n",
            "14 TestSet accuracy: 0.1008\n",
            "16 TestSet accuracy: 0.1\n",
            "18 TestSet accuracy: 0.1\n",
            "20 TestSet accuracy: 0.1\n",
            "22 TestSet accuracy: 0.1\n",
            "24 TestSet accuracy: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLao19_Pw5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDEEjsoPw5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbPZj2kXPw5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEV5XqeIPw5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGLLYSCLPw5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I37Vb9_WPw5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neBS6mFAPw5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6O-hiuxPw5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE5o96B2Pw5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR43IugGPw5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMCXlBPhPw5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwjMmHNPw5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOkkbAOvPw54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}